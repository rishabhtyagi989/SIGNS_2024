{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_weighted_average(sentiment_scores, decay_factor):\n",
    "    \"\"\"\n",
    "    Calculate a balanced weighted average of sentiment scores without biasing towards negative values.\n",
    "    \n",
    "    Parameters:\n",
    "    - sentiment_scores: A list or pandas Series of sentiment scores (positive and negative).\n",
    "    - decay_factor: A value between 0 and 1 to control the decay rate of weights; defaults to 0.95.\n",
    "    \n",
    "    Returns:\n",
    "    - A single balanced weighted average score.\n",
    "    \"\"\"\n",
    "    # Initialize positive and negative scores with respective weights\n",
    "    positive_scores = sentiment_scores[sentiment_scores > 0]\n",
    "    negative_scores = sentiment_scores[sentiment_scores < 0]\n",
    "    \n",
    "    # Calculate decay weights for each score in reverse order (older scores get smaller weights)\n",
    "    decay_weights = decay_factor ** np.arange(len(sentiment_scores))[::-1]\n",
    "\n",
    "    # Separate weights for positive and negative scores\n",
    "    pos_weights = decay_weights[:len(positive_scores)]\n",
    "    neg_weights = decay_weights[:len(negative_scores)]\n",
    "\n",
    "    # Calculate the weighted average for positive and negative scores separately\n",
    "    pos_weighted_avg = (positive_scores * pos_weights).sum() / pos_weights.sum() if len(pos_weights) > 0 else 0\n",
    "    neg_weighted_avg = (negative_scores * neg_weights).sum() / neg_weights.sum() if len(neg_weights) > 0 else 0\n",
    "\n",
    "    # Return the balanced average by combining positive and negative averages equally\n",
    "    balanced_avg = (pos_weighted_avg + neg_weighted_avg) / 2\n",
    "\n",
    "    return balanced_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stock_sentiment_changes(stock_symbols, interval_days, decay_factor, start_date, end_date, include_news_sentiment):\n",
    "    \"\"\"\n",
    "    Computes stock sentiment and related metrics, with an option to include/exclude news sentiment scores.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_symbols: List of stock symbols to process.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - decay_factor: Decay factor for sentiment weighting.\n",
    "    - start_date: Start date for data filtering.\n",
    "    - end_date: End date for data filtering.\n",
    "    - include_news_sentiment: Boolean indicating whether to include news sentiment scores.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing results DataFrame for each stock symbol.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to hold data\n",
    "    df_stock_news_sentiment_scores_dict = {}\n",
    "    df_news_sentiment_scores_dict = {}\n",
    "    df_stock_data_dict = {}\n",
    "    results = {}\n",
    "\n",
    "    # Ensure start_date and end_date are datetime.date objects\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Load data and convert date columns to datetime.date\n",
    "        try:\n",
    "            df_stock_news_sentiment_scores_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/Sentiment_scores/stock_news_sentiment_scores/stock_news_sentiment_analysis_results_{symbol}.csv')\n",
    "            if include_news_sentiment:\n",
    "                df_news_sentiment_scores_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/Sentiment_scores/news_sentiment_scores/2000-2024/sentiment_analysis_results_{symbol}.csv')\n",
    "            df_stock_data_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/stocks data/stock_data_{symbol}.csv')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading data for {symbol}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns to distinguish sentiment sources\n",
    "        if include_news_sentiment:\n",
    "            df_news_sentiment_scores_dict[symbol] = df_news_sentiment_scores_dict[symbol].rename(columns={'weighted compound sentiment score': 'weighted compound news sentiment score'})\n",
    "        df_stock_news_sentiment_scores_dict[symbol] = df_stock_news_sentiment_scores_dict[symbol].rename(columns={'weighted compound sentiment score': 'weighted compound stock sentiment score'})\n",
    "\n",
    "        # Convert 'Date' to datetime.date format\n",
    "        dataframes = [df_stock_news_sentiment_scores_dict[symbol], df_stock_data_dict[symbol]]\n",
    "        if include_news_sentiment:\n",
    "            dataframes.append(df_news_sentiment_scores_dict[symbol])\n",
    "\n",
    "        for df in dataframes:\n",
    "            df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "        # Filter data within date range\n",
    "        filtered_stock_sentiment = df_stock_news_sentiment_scores_dict[symbol][\n",
    "            (df_stock_news_sentiment_scores_dict[symbol]['Date'] >= start_date) & \n",
    "            (df_stock_news_sentiment_scores_dict[symbol]['Date'] <= end_date)\n",
    "        ]\n",
    "        if include_news_sentiment:\n",
    "            filtered_news_sentiment = df_news_sentiment_scores_dict[symbol][\n",
    "                (df_news_sentiment_scores_dict[symbol]['Date'] >= start_date) & \n",
    "                (df_news_sentiment_scores_dict[symbol]['Date'] <= end_date)\n",
    "            ]\n",
    "        filtered_stock = df_stock_data_dict[symbol][\n",
    "            (df_stock_data_dict[symbol]['Date'] >= start_date) & \n",
    "            (df_stock_data_dict[symbol]['Date'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        # Merge data on 'Date'\n",
    "        merged_data = filtered_stock_sentiment\n",
    "        if include_news_sentiment:\n",
    "            merged_data = pd.merge(merged_data, filtered_news_sentiment, on='Date', how='inner')\n",
    "        merged_data = pd.merge(merged_data, filtered_stock, on='Date', how='inner')\n",
    "        merged_data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "        # Check if data is sufficient\n",
    "        if len(merged_data) < interval_days:\n",
    "            print(f\"Not enough data for {symbol} with interval_days = {interval_days}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize lists to store results\n",
    "        price_diff_list = []\n",
    "        balanced_avg_stock_sentiment_list = []\n",
    "        balanced_avg_news_sentiment_list = [] if include_news_sentiment else None\n",
    "        sma_list = []\n",
    "        sma_diff_list = []\n",
    "        date_list = []\n",
    "\n",
    "        # Calculate metrics\n",
    "        for i in range(len(merged_data) - interval_days + 1):\n",
    "            date_d = merged_data['Date'].iloc[i + interval_days - 1]\n",
    "\n",
    "            # Calculate price difference\n",
    "            close_d = merged_data['Close'].iloc[i]\n",
    "            close_d_T = merged_data['Close'].iloc[i + interval_days - 1]\n",
    "            price_diff = close_d_T - close_d\n",
    "\n",
    "            # Calculate SMA\n",
    "            sma = merged_data['Close'].iloc[i:i + interval_days].mean()\n",
    "\n",
    "            # Calculate balanced weighted averages for sentiments\n",
    "            stock_sentiment_scores = merged_data['weighted compound stock sentiment score'].iloc[i:i + interval_days]\n",
    "            balanced_avg_stock_sentiment = balanced_weighted_average(stock_sentiment_scores, decay_factor)\n",
    "\n",
    "            if include_news_sentiment:\n",
    "                news_sentiment_scores = merged_data['weighted compound news sentiment score'].iloc[i:i + interval_days]\n",
    "                balanced_avg_news_sentiment = balanced_weighted_average(news_sentiment_scores, decay_factor)\n",
    "\n",
    "            # Calculate SMA difference (classification)\n",
    "            if len(sma_list) > 0:  # Ensure there is a previous SMA value to compare\n",
    "                prev_sma = sma_list[-1]\n",
    "                sma_diff = 0 if prev_sma > sma else 1\n",
    "            else:\n",
    "                sma_diff = np.nan  # For the first interval, there is no previous SMA to compare\n",
    "\n",
    "            # Append results\n",
    "            date_list.append(date_d)\n",
    "            price_diff_list.append(price_diff)\n",
    "            sma_list.append(sma)\n",
    "            sma_diff_list.append(sma_diff)\n",
    "            balanced_avg_stock_sentiment_list.append(balanced_avg_stock_sentiment)\n",
    "            if include_news_sentiment:\n",
    "                balanced_avg_news_sentiment_list.append(balanced_avg_news_sentiment)\n",
    "\n",
    "        # Store results for the symbol\n",
    "        results[symbol] = pd.DataFrame({\n",
    "            'Date': date_list,\n",
    "            f'{symbol}_Price_Diff_{interval_days}d': price_diff_list,\n",
    "            f'{symbol}_SMA_{interval_days}d': sma_list,\n",
    "            f'{symbol}_SMA_Diff_{interval_days}d': sma_diff_list,\n",
    "            f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d': balanced_avg_stock_sentiment_list\n",
    "        })\n",
    "\n",
    "        if include_news_sentiment:\n",
    "            results[symbol][f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'] = balanced_avg_news_sentiment_list\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = ['GOOG', 'MSFT', 'NVDA','AMZN','AAPL']\n",
    "interval_days = 14\n",
    "decay_factor = 0.60\n",
    "results = compute_stock_sentiment_changes(stock_symbols, interval_days, decay_factor, start_date='2011-05-16', end_date='2024-09-21', include_news_sentiment = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Price_Diff_14d</th>\n",
       "      <th>AAPL_SMA_14d</th>\n",
       "      <th>AAPL_SMA_Diff_14d</th>\n",
       "      <th>AAPL_Balanced_Avg_Stock_Sentiment_14d</th>\n",
       "      <th>AAPL_Balanced_Avg_News_Sentiment_14d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-23</td>\n",
       "      <td>6.451735</td>\n",
       "      <td>15.218639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082914</td>\n",
       "      <td>0.101592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-15</td>\n",
       "      <td>7.060843</td>\n",
       "      <td>16.007199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046834</td>\n",
       "      <td>0.077620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>5.655769</td>\n",
       "      <td>16.580228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122351</td>\n",
       "      <td>0.078132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>5.732059</td>\n",
       "      <td>17.112691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028113</td>\n",
       "      <td>0.078684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>12.186655</td>\n",
       "      <td>17.941331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>54.826340</td>\n",
       "      <td>192.633856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>-0.079817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>49.132828</td>\n",
       "      <td>196.138356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030154</td>\n",
       "      <td>-0.079631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>48.463730</td>\n",
       "      <td>199.606464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>-0.077080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>39.411926</td>\n",
       "      <td>202.302616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>-0.084794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>44.208511</td>\n",
       "      <td>206.510582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-0.083824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  AAPL_Price_Diff_14d  AAPL_SMA_14d  AAPL_SMA_Diff_14d  \\\n",
       "0    2014-04-23             6.451735     15.218639                NaN   \n",
       "1    2014-07-15             7.060843     16.007199                1.0   \n",
       "2    2014-10-01             5.655769     16.580228                1.0   \n",
       "3    2015-01-15             5.732059     17.112691                1.0   \n",
       "4    2015-07-20            12.186655     17.941331                1.0   \n",
       "..          ...                  ...           ...                ...   \n",
       "132  2024-07-19            54.826340    192.633856                1.0   \n",
       "133  2024-07-24            49.132828    196.138356                1.0   \n",
       "134  2024-07-26            48.463730    199.606464                1.0   \n",
       "135  2024-08-06            39.411926    202.302616                1.0   \n",
       "136  2024-08-28            44.208511    206.510582                1.0   \n",
       "\n",
       "     AAPL_Balanced_Avg_Stock_Sentiment_14d  \\\n",
       "0                                 0.082914   \n",
       "1                                 0.046834   \n",
       "2                                 0.122351   \n",
       "3                                 0.028113   \n",
       "4                                 0.028216   \n",
       "..                                     ...   \n",
       "132                               0.092503   \n",
       "133                               0.030154   \n",
       "134                               0.015207   \n",
       "135                              -0.024605   \n",
       "136                              -0.000941   \n",
       "\n",
       "     AAPL_Balanced_Avg_News_Sentiment_14d  \n",
       "0                                0.101592  \n",
       "1                                0.077620  \n",
       "2                                0.078132  \n",
       "3                                0.078684  \n",
       "4                                0.005379  \n",
       "..                                    ...  \n",
       "132                             -0.079817  \n",
       "133                             -0.079631  \n",
       "134                             -0.077080  \n",
       "135                             -0.084794  \n",
       "136                             -0.083824  \n",
       "\n",
       "[137 rows x 6 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sentiments_vs_metric_as_mlr(stock_symbols, results, interval_days, metric):\n",
    "    \"\"\"\n",
    "    Fits multilinear regression of sentiment scores against either SMA or price difference.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_symbols: List of stock symbols to process.\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - metric: Specify either 'sma' or 'price_diff' to choose which metric to plot.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing models and MSEs for each stock symbol.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store linear models and MSEs\n",
    "    mlr_model = {}\n",
    "    mlr_mses = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Construct column names based on the actual interval_days and selected metric\n",
    "        news_sentiment_col = f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "        stock_sentiment_col = f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "        if metric == 'sma':\n",
    "            metric_col = f'{symbol}_SMA_{interval_days}d'\n",
    "        elif metric == 'price_diff':\n",
    "            metric_col = f'{symbol}_Price_Diff_{interval_days}d'\n",
    "        else:\n",
    "            print(f\"Unknown metric '{metric}'. Choose 'sma' or 'price_diff'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Check if the expected columns exist in the DataFrame for the current symbol\n",
    "        if (\n",
    "            symbol in results and \n",
    "            news_sentiment_col in results[symbol].columns and \n",
    "            stock_sentiment_col in results[symbol].columns and \n",
    "            metric_col in results[symbol].columns\n",
    "        ):\n",
    "            # Extract features (sentiment columns) and target (metric column)\n",
    "            X = results[symbol][[news_sentiment_col, stock_sentiment_col]].values\n",
    "            y = results[symbol][metric_col].values\n",
    "\n",
    "            # Fit a multilinear regression model\n",
    "            pipeline = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('mlr', LinearRegression())\n",
    "            ])\n",
    "            pipeline.fit(X, y)\n",
    "            y_pred = pipeline.predict(X)\n",
    "\n",
    "            # Store the model and MSE\n",
    "            mlr_model[symbol] = pipeline\n",
    "            mlr_mses[symbol] = mse(y, y_pred)\n",
    "\n",
    "            print(f\"{symbol}: Model fitted. MSE = {mlr_mses[symbol]:.4f}\")\n",
    "        else:\n",
    "            print(f\"Required columns for {symbol} with interval {interval_days} days not found. Skipping.\")\n",
    "\n",
    "    return {'models': mlr_model, 'mse': mlr_mses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required columns for GOOG with interval 14 days not found. Skipping.\n",
      "Required columns for MSFT with interval 14 days not found. Skipping.\n",
      "Required columns for NVDA with interval 14 days not found. Skipping.\n",
      "Required columns for AMZN with interval 14 days not found. Skipping.\n",
      "Required columns for AAPL with interval 14 days not found. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'models': {}, 'mse': {}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_sentiments_vs_metric_as_mlr(stock_symbols, results, interval_days, 'sma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multilinear_regression(results, stock_symbol, interval_days, metric):\n",
    "    \"\"\"\n",
    "    Runs a multilinear regression of balanced average news and stock sentiment scores\n",
    "    against either SMA or price difference.\n",
    "\n",
    "    Parameters:\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - stock_symbol: The symbol of the stock to analyze.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - metric: Specify either 'sma' or 'price_diff' to choose which metric to analyze.\n",
    "    \"\"\"\n",
    "    # Define column names based on interval_days and selected metric\n",
    "    balanced_avg_news_sentiment_col = f'{stock_symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "    balanced_avg_stock_sentiment_col = f'{stock_symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "    if metric == 'sma':\n",
    "        metric_col = f'{stock_symbol}_SMA_{interval_days}d'\n",
    "    elif metric == 'price_diff':\n",
    "        metric_col = f'{stock_symbol}_Price_Diff_{interval_days}d'\n",
    "    else:\n",
    "        print(f\"Unknown metric '{metric}'. Choose 'sma' or 'price_diff'.\")\n",
    "        return\n",
    "\n",
    "    # Check if the required columns exist in the DataFrame\n",
    "    if stock_symbol in results and \\\n",
    "       balanced_avg_news_sentiment_col in results[stock_symbol].columns and \\\n",
    "       balanced_avg_stock_sentiment_col in results[stock_symbol].columns and \\\n",
    "       metric_col in results[stock_symbol].columns:\n",
    "        \n",
    "        # Extract predictor variables and the dependent variable\n",
    "        X_news = np.array(results[stock_symbol][balanced_avg_news_sentiment_col])\n",
    "        X_stock = np.array(results[stock_symbol][balanced_avg_stock_sentiment_col])\n",
    "        y_stats = np.array(results[stock_symbol][metric_col])\n",
    "        \n",
    "        # Combine predictors into a single 2D array\n",
    "        X_combined = np.column_stack((X_news, X_stock))\n",
    "        \n",
    "        # Add a constant to the predictors for the intercept\n",
    "        X_with_const = sm.add_constant(X_combined)\n",
    "\n",
    "        # Fit the OLS model\n",
    "        model_ols = sm.OLS(y_stats, X_with_const)\n",
    "        results_ols = model_ols.fit()\n",
    "\n",
    "        # Print the summary to see coefficients and other statistics\n",
    "        print(results_ols.summary())\n",
    "\n",
    "        # Get the confidence intervals for the coefficients\n",
    "        confidence_intervals = results_ols.conf_int(alpha=0.05)  # 95% CI by default\n",
    "        print(\"Confidence intervals:\\n\", confidence_intervals)\n",
    "    else:\n",
    "        print(f\"Required columns for {stock_symbol} with interval {interval_days} days and metric '{metric}' not found in results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.336\n",
      "Model:                            OLS   Adj. R-squared:                  0.326\n",
      "Method:                 Least Squares   F-statistic:                     33.89\n",
      "Date:                Sun, 17 Nov 2024   Prob (F-statistic):           1.23e-12\n",
      "Time:                        22:45:40   Log-Likelihood:                -737.66\n",
      "No. Observations:                 137   AIC:                             1481.\n",
      "Df Residuals:                     134   BIC:                             1490.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        100.2348      5.400     18.561      0.000      89.554     110.916\n",
      "x1          -444.2492     57.400     -7.740      0.000    -557.776    -330.722\n",
      "x2           152.0793     70.396      2.160      0.033      12.849     291.310\n",
      "==============================================================================\n",
      "Omnibus:                        1.047   Durbin-Watson:                   0.207\n",
      "Prob(Omnibus):                  0.592   Jarque-Bera (JB):                1.065\n",
      "Skew:                          -0.096   Prob(JB):                        0.587\n",
      "Kurtosis:                       2.613   Cond. No.                         15.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Confidence intervals:\n",
      " [[  89.55413155  110.9155196 ]\n",
      " [-557.77610027 -330.7223673 ]\n",
      " [  12.848706    291.30989968]]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "stock_symbol = 'AAPL'\n",
    "metric = 'sma'  \n",
    "\n",
    "# Run the multilinear regression\n",
    "run_multilinear_regression(results, stock_symbol, interval_days, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sentiments_vs_metric_as_log_reg(stock_symbols, results, interval_days, include_news_sentiment):\n",
    "    \"\"\"\n",
    "    Fits logistic regression and calculates accuracy and specificity with an option to include/exclude news sentiment scores.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_symbols: List of stock symbols to process.\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - include_news_sentiment: Boolean indicating whether to include news sentiment scores as features.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing models and confusion matrices for each stock symbol.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store models, confusion matrices, and metrics\n",
    "    model = {}\n",
    "    metrics = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Construct column names\n",
    "        stock_sentiment_col = f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "        news_sentiment_col = f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "        metric_col = f'{symbol}_SMA_Diff_{interval_days}d'\n",
    "\n",
    "        # Check if required columns exist\n",
    "        if symbol in results and stock_sentiment_col in results[symbol].columns and metric_col in results[symbol].columns:\n",
    "            if include_news_sentiment and news_sentiment_col in results[symbol].columns:\n",
    "                # Include both stock and news sentiment as features\n",
    "                data = results[symbol][[news_sentiment_col, stock_sentiment_col, metric_col]].dropna()\n",
    "                X = data[[news_sentiment_col, stock_sentiment_col]].values\n",
    "            else:\n",
    "                # Include only stock sentiment as features\n",
    "                data = results[symbol][[stock_sentiment_col, metric_col]].dropna()\n",
    "                X = data[[stock_sentiment_col]].values\n",
    "\n",
    "            y = data[metric_col].values\n",
    "\n",
    "            # Fit logistic regression\n",
    "            pipeline = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('log_reg', LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000))\n",
    "            ])\n",
    "            pipeline.fit(X, y)\n",
    "            y_pred = pipeline.predict(X)\n",
    "\n",
    "            # Compute confusion matrix\n",
    "            tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "            # Store results\n",
    "            model[symbol] = pipeline\n",
    "            metrics[symbol] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"specificity\": specificity\n",
    "            }\n",
    "\n",
    "            # Print results\n",
    "            print(f\"{symbol}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Specificity: {specificity:.4f}\")\n",
    "        else:\n",
    "            print(f\"Required columns for {symbol} with interval {interval_days} days not found. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG:\n",
      "Accuracy: 0.8732\n",
      "Specificity: 0.0000\n",
      "MSFT:\n",
      "Accuracy: 0.8323\n",
      "Specificity: 0.0000\n",
      "NVDA:\n",
      "Accuracy: 0.9853\n",
      "Specificity: 0.0000\n",
      "AMZN:\n",
      "Accuracy: 0.6926\n",
      "Specificity: 0.0870\n",
      "AAPL:\n",
      "Accuracy: 0.7794\n",
      "Specificity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "fit_sentiments_vs_metric_as_log_reg(stock_symbols, results, interval_days, include_news_sentiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sentiments_vs_metric_as_xgb(stock_symbols, results, interval_days, include_news_sentiment):\n",
    "    \"\"\"\n",
    "    Fits XGBoost classifiers and calculates accuracy and specificity with an option to include/exclude news sentiment scores.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_symbols: List of stock symbols to process.\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - include_news_sentiment: Boolean indicating whether to include news sentiment scores as features.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing models and metrics for each stock symbol.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store models and metrics\n",
    "    model = {}\n",
    "    metrics = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Construct column names\n",
    "        stock_sentiment_col = f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "        news_sentiment_col = f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "        metric_col = f'{symbol}_SMA_Diff_{interval_days}d'\n",
    "\n",
    "        # Check if required columns exist\n",
    "        if symbol in results and stock_sentiment_col in results[symbol].columns and metric_col in results[symbol].columns:\n",
    "            # Build features and target\n",
    "            if include_news_sentiment and news_sentiment_col in results[symbol].columns:\n",
    "                data = results[symbol][[news_sentiment_col, stock_sentiment_col, metric_col]].dropna()\n",
    "                X = data[[news_sentiment_col, stock_sentiment_col]].values\n",
    "            else:\n",
    "                data = results[symbol][[stock_sentiment_col, metric_col]].dropna()\n",
    "                X = data[[stock_sentiment_col]].values\n",
    "            \n",
    "            y = data[metric_col].values\n",
    "\n",
    "            # Compute scale_pos_weight for class imbalance\n",
    "            scale_pos_weight = len(y[y == 0]) / len(y[y == 1]) if len(y[y == 1]) > 0 else 1\n",
    "\n",
    "            # Fit XGBoost model\n",
    "            xgb_model = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "            xgb_model.fit(X, y)\n",
    "            y_pred = xgb_model.predict(X)\n",
    "\n",
    "            # Compute confusion matrix\n",
    "            tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            f1 = f1_score(y, y_pred)\n",
    "            roc_auc = roc_auc_score(y, xgb_model.predict_proba(X)[:, 1])\n",
    "\n",
    "            # Store results\n",
    "            model[symbol] = xgb_model\n",
    "            metrics[symbol] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"specificity\": specificity,\n",
    "                \"f1_score\": f1,\n",
    "                \"roc_auc\": roc_auc\n",
    "            }\n",
    "\n",
    "            # Print results\n",
    "            print(f\"{symbol}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Specificity: {specificity:.4f}\")\n",
    "            print(f\"F1-Score: {f1:.4f}\")\n",
    "            print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Required columns for {symbol} with interval {interval_days} days not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhbhardwaj/miniconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:23:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/rishabhbhardwaj/miniconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:23:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG:\n",
      "Accuracy: 0.9085\n",
      "Specificity: 0.9444\n",
      "F1-Score: 0.9451\n",
      "ROC-AUC: 0.9828\n",
      "MSFT:\n",
      "Accuracy: 0.9701\n",
      "Specificity: 1.0000\n",
      "F1-Score: 0.9817\n",
      "ROC-AUC: 0.9979\n",
      "NVDA:\n",
      "Accuracy: 0.0147\n",
      "Specificity: 1.0000\n",
      "F1-Score: 0.0000\n",
      "ROC-AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhbhardwaj/miniconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:23:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/rishabhbhardwaj/miniconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:23:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/rishabhbhardwaj/miniconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:23:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1724807611129/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN:\n",
      "Accuracy: 0.9654\n",
      "Specificity: 0.9928\n",
      "F1-Score: 0.9748\n",
      "ROC-AUC: 0.9981\n",
      "AAPL:\n",
      "Accuracy: 0.9706\n",
      "Specificity: 1.0000\n",
      "F1-Score: 0.9811\n",
      "ROC-AUC: 0.9983\n"
     ]
    }
   ],
   "source": [
    "fit_sentiments_vs_metric_as_xgb(stock_symbols, results, interval_days, include_news_sentiment = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
